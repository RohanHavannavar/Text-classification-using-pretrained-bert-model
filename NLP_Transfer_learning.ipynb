{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6JSKPjKwOLP"
      },
      "source": [
        "#in this assignment you need two files reviews.csv and tokenization file\n",
        "#you can use gdown module to import both the files in colab from Google drive\n",
        "#the syntax is for gdown is !gdown --id file_id\n",
        "#please run the below cell to import the required files\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUGbEZafwwzX",
        "outputId": "84e65666-ecdd-4616-9d83-bb502ac7ade6"
      },
      "source": [
        "# !gdown --id 1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
        "# !gdown --id 13exfXiyiByluh1PfYK1EyZyizqxeCVG9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt\n",
            "To: /content/Reviews.csv\n",
            "100% 301M/301M [00:02<00:00, 116MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13exfXiyiByluh1PfYK1EyZyizqxeCVG9\n",
            "To: /content/tokenization.py\n",
            "100% 17.3k/17.3k [00:00<00:00, 29.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tokenization.py file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GWo92EaXYzA8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "77481b4a-ec39-456e-f49c-6acbebe9b1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd238f27-7d60-4ccc-a4c9-83c44b775ef3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd238f27-7d60-4ccc-a4c9-83c44b775ef3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving tokenization.py to tokenization.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --header=\"Host: doc-0s-28-docs.googleusercontent.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9,es;q=0.8\" --header=\"Cookie: AUTH_aqmiu8cqc1f1lojhbu2jg4sa8f3f6flv_nonce=thn6cqm3b4422\" --header=\"Connection: keep-alive\" \"https://doc-0s-28-docs.googleusercontent.com/docs/securesc/jv3127n68jq8qbmmapl9igngebo10mfu/gf1momqergkgrbunqp27gpv2n5ine6g8/1647759450000/18338633539012077285/17457919835615455873/1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt?e=download&ax=ACxEAsZmbjO0H89Wq_gV1rBAyqCp_SlFxNJb0HQ6Iz_1LdA7Oi8cOWDN2J9tbVwaSjMpCKTTVLbVlGLc6OoHxxkEHOH9hgP8CMa4obL5UxEfzi_1iCCLUmZlLUaoPnfO2ubUHx2pMIwkXA5ws2A9ZPa-Dk0ZcY6KJVm0XLrAnXEt86WW-ciKVYLLo7NUT6uXUkow_LShjJqT-SUA9UDMBwejkl6aNzKBJuABtkiArd1I6dnoy0V5JLv9IEjzRQDBnozgHOc89tMlTEUNPTnHZ1fkdbFaCrMSwaLVUcPkYjULvjQjn8EYsGTyXKYLdCXby8EOQjp3YpCmOv0XBSAgG7TxaeYsytWE-f2sbQzw17S09L4ZorJyLUMaY1_aUJGXu4LsdbkpkfAjzNX_w8Wm9KJfusWObzPgRaoAuCsJOyz27Lp7pR81BGsFEnb0jU7vS8PjEQ_DyVrvDHynsv20P-cZPVwKVcUbdRi9ziDATIEp-CZb_jB0EtXrBakbdhlyqwdcY-GAIUz082jvlxtKJedWOI-x-j8DwuoDHHyArhoi9W1t3zXqQ4Z5k5FHEQYTAkYry-leqvm_oiS87A7MVooSHTMfQ7_adceIo3BJcuLfDlB5aF9AS1cNMFr4mFTUxih78FQi0RMSjmId_8qvB5p6yMK8gTT2tGAKhuE0QTxH39IjJIAvhiZDS8Oxw91cYHOgPkldU2rmy2CbjN-YTedgShhnMfi0N10C9epgI9HgJ9mzAR9jQAw&authuser=0&nonce=thn6cqm3b4422&user=17457919835615455873&hash=nqsc362cudibuc785grkbdv2np51hpbm\" -c -O 'Reviews.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmBLfGXnfy_j",
        "outputId": "37668696-2e1f-4118-84cd-58d4341c87dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-20 06:58:54--  https://doc-0s-28-docs.googleusercontent.com/docs/securesc/jv3127n68jq8qbmmapl9igngebo10mfu/gf1momqergkgrbunqp27gpv2n5ine6g8/1647759450000/18338633539012077285/17457919835615455873/1GsD8JlAc_0yJ-1151LNr6rLw83RRUPgt?e=download&ax=ACxEAsZmbjO0H89Wq_gV1rBAyqCp_SlFxNJb0HQ6Iz_1LdA7Oi8cOWDN2J9tbVwaSjMpCKTTVLbVlGLc6OoHxxkEHOH9hgP8CMa4obL5UxEfzi_1iCCLUmZlLUaoPnfO2ubUHx2pMIwkXA5ws2A9ZPa-Dk0ZcY6KJVm0XLrAnXEt86WW-ciKVYLLo7NUT6uXUkow_LShjJqT-SUA9UDMBwejkl6aNzKBJuABtkiArd1I6dnoy0V5JLv9IEjzRQDBnozgHOc89tMlTEUNPTnHZ1fkdbFaCrMSwaLVUcPkYjULvjQjn8EYsGTyXKYLdCXby8EOQjp3YpCmOv0XBSAgG7TxaeYsytWE-f2sbQzw17S09L4ZorJyLUMaY1_aUJGXu4LsdbkpkfAjzNX_w8Wm9KJfusWObzPgRaoAuCsJOyz27Lp7pR81BGsFEnb0jU7vS8PjEQ_DyVrvDHynsv20P-cZPVwKVcUbdRi9ziDATIEp-CZb_jB0EtXrBakbdhlyqwdcY-GAIUz082jvlxtKJedWOI-x-j8DwuoDHHyArhoi9W1t3zXqQ4Z5k5FHEQYTAkYry-leqvm_oiS87A7MVooSHTMfQ7_adceIo3BJcuLfDlB5aF9AS1cNMFr4mFTUxih78FQi0RMSjmId_8qvB5p6yMK8gTT2tGAKhuE0QTxH39IjJIAvhiZDS8Oxw91cYHOgPkldU2rmy2CbjN-YTedgShhnMfi0N10C9epgI9HgJ9mzAR9jQAw&authuser=0&nonce=thn6cqm3b4422&user=17457919835615455873&hash=nqsc362cudibuc785grkbdv2np51hpbm\n",
            "Resolving doc-0s-28-docs.googleusercontent.com (doc-0s-28-docs.googleusercontent.com)... 173.194.215.132, 2607:f8b0:400c:c0c::84\n",
            "Connecting to doc-0s-28-docs.googleusercontent.com (doc-0s-28-docs.googleusercontent.com)|173.194.215.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 300904694 (287M) [text/csv]\n",
            "Saving to: ‘Reviews.csv’\n",
            "\n",
            "Reviews.csv         100%[===================>] 286.96M   111MB/s    in 2.6s    \n",
            "\n",
            "2022-03-20 06:58:57 (111 MB/s) - ‘Reviews.csv’ saved [300904694/300904694]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOtG4cf0qVAZ"
      },
      "source": [
        "#all imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcmiHdAJqVAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a4d48f9-e0d1-406d-dd37-8ecbf9aa3322"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBsay58AqVAo"
      },
      "source": [
        "<font size=4>Grader function 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTBvOKFeqVAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff7b667-de7f-4969-942c-f96fd5fc9a4a"
      },
      "source": [
        "def grader_tf_version():\n",
        "    assert((tf.__version__)>'2')\n",
        "    return True\n",
        "grader_tf_version()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTWRqbrBqVAu"
      },
      "source": [
        "<pre><font size=6>Part-1: Preprocessing</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3csZKDrqVAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95b1e70-0548-40e3-8867-7dcfec721a6a"
      },
      "source": [
        "#Read the dataset - Amazon fine food reviews\n",
        "reviews = pd.read_csv(r\"Reviews.csv\")\n",
        "#check the info of the dataset\n",
        "reviews.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568438 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xokNn7qZqVAz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "dcc60815-aa24-43b9-8725-1ac424f07be2"
      },
      "source": [
        "#get only 2 columns - Text, Score\n",
        "#drop the NAN values\n",
        "reviews = reviews[['Text','Score']]\n",
        "reviews.dropna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     Text  Score\n",
              "0       I have bought several of the Vitality canned d...      5\n",
              "1       Product arrived labeled as Jumbo Salted Peanut...      1\n",
              "2       This is a confection that has been around a fe...      4\n",
              "3       If you are looking for the secret ingredient i...      2\n",
              "4       Great taffy at a great price.  There was a wid...      5\n",
              "...                                                   ...    ...\n",
              "568449  Great for sesame chicken..this is a good if no...      5\n",
              "568450  I'm disappointed with the flavor. The chocolat...      2\n",
              "568451  These stars are small, so you can give 10-15 o...      5\n",
              "568452  These are the BEST treats for training and rew...      5\n",
              "568453  I am very satisfied ,product is as advertised,...      5\n",
              "\n",
              "[568454 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f117c9c-9882-4984-a02d-d95d9f8ae3dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>Great for sesame chicken..this is a good if no...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>These stars are small, so you can give 10-15 o...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>These are the BEST treats for training and rew...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>I am very satisfied ,product is as advertised,...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f117c9c-9882-4984-a02d-d95d9f8ae3dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f117c9c-9882-4984-a02d-d95d9f8ae3dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f117c9c-9882-4984-a02d-d95d9f8ae3dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GZt7pVkqVA4"
      },
      "source": [
        "#if score> 3, set score = 1\n",
        "#if score<=2, set score = 0\n",
        "#if score == 3, remove the rows. \n",
        "def score_set(i):\n",
        "  if(i>3):\n",
        "    return 1\n",
        "  elif(i<=2):\n",
        "    return 0\n",
        "  elif(i == 3):\n",
        "    return 2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['s'] = reviews['Score'].apply(score_set)"
      ],
      "metadata": {
        "id": "k6mZ_P93pMCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.drop('Score',axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "U1Aix8b5M3xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.rename(columns = {'s':'Score'},inplace = True)"
      ],
      "metadata": {
        "id": "0fSS3sG9PfTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing all the rows where score value  = 2\n",
        "indexes = reviews[reviews['Score'] == 2].index\n",
        "reviews.drop(indexes,inplace = True)"
      ],
      "metadata": {
        "id": "OHZPGpjSPmtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNPEiqDkQ9qM",
        "outputId": "17a1e0ca-8593-42e9-8b18-b1ca12c846cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(525814, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVe8LlkrqVA6"
      },
      "source": [
        "<font size=4>Grader function 2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mDXSiJpqVA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9621d2-7a49-4eca-a7f2-0752388b67f8"
      },
      "source": [
        "def grader_reviews():\n",
        "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
        "    assert(temp_shape == True)\n",
        "    return True\n",
        "grader_reviews()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYZ-UB9UqVA-"
      },
      "source": [
        "def get_wordlen(x):\n",
        "    return len(x.split())\n",
        "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
        "reviews = reviews[reviews.len<50]\n",
        "reviews = reviews.sample(n=100000, random_state=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvldQriGqVBB"
      },
      "source": [
        "#remove HTML from the Text column and save in the Text column only\n",
        "#https://stackoverflow.com/questions/3398852/using-python-remove-html-tags-formatting-from-a-string\n",
        "import re\n",
        "def remove_html(data):\n",
        "  p = re.compile(r'<.*?>')\n",
        "  return p.sub('', data)\n",
        "\n",
        "reviews['Text'] = reviews['Text'].apply(remove_html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhfN1s2mqVBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "22f16263-4146-4513-a899-9f786d5fc547"
      },
      "source": [
        "#print head 5\n",
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     Text  Score  len\n",
              "64117   The tea was of great quality and it tasted lik...      1   30\n",
              "418112  My cat loves this.  The pellets are nice and s...      1   31\n",
              "357829  Great product. Does not completely get rid of ...      1   41\n",
              "175872  This gum is my favorite!  I would advise every...      1   27\n",
              "178716  I also found out about this product because of...      1   22"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e1750ed-c407-420d-8a35-69f4b0bf8455\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64117</th>\n",
              "      <td>The tea was of great quality and it tasted lik...</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418112</th>\n",
              "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357829</th>\n",
              "      <td>Great product. Does not completely get rid of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175872</th>\n",
              "      <td>This gum is my favorite!  I would advise every...</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178716</th>\n",
              "      <td>I also found out about this product because of...</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e1750ed-c407-420d-8a35-69f4b0bf8455')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e1750ed-c407-420d-8a35-69f4b0bf8455 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e1750ed-c407-420d-8a35-69f4b0bf8455');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsYDd3okqVBF"
      },
      "source": [
        "#split the data into train and test data(20%) with Stratify sampling, random state 33, \n",
        "from sklearn.model_selection import train_test_split\n",
        "y = reviews['Score']\n",
        "x = reviews.drop('Score',axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 33,stratify=y)\n"
      ],
      "metadata": {
        "id": "wWy2JKyhU_YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q6OAcrOqVBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "c85167c8-4f36-4559-f063-1e4e8c7d1601"
      },
      "source": [
        "#plot bar graphs of y_train and y_test\n",
        "y_train.value_counts().plot.bar(figsize = (6,6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6ba8551690>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts().plot.bar(figsize = (6,6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "-hvDP1HaX5ou",
        "outputId": "74e0956d-eb0b-440e-9900-41a00a6a68fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6ba56bae50>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-z5boWqVBK"
      },
      "source": [
        "#saving to disk. if we need, we can load preprocessed data directly. \n",
        "reviews.to_csv('preprocessed.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading preprocessed.csv\n",
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "odd_YgjsOqnL",
        "outputId": "c08283fa-f022-4b81-d041-85b49f344193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e845ff90-80c9-433f-b58e-cb9ef95579f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e845ff90-80c9-433f-b58e-cb9ef95579f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving preprocessed.csv to preprocessed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = pd.read_csv('preprocessed.csv')"
      ],
      "metadata": {
        "id": "ye9ovPXULopB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = reviews['Score']\n",
        "x = reviews.drop('Score',axis = 1)"
      ],
      "metadata": {
        "id": "uN-OOMfuO14A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 33,stratify=y)"
      ],
      "metadata": {
        "id": "eFGtbJbKLvWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBtqNGN9qVBM"
      },
      "source": [
        "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
        "\n",
        "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
        "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
        "\n",
        "\n",
        "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
        "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8xd2HejqVBN"
      },
      "source": [
        "## Loading the Pretrained Model from tensorflow HUB\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
        "max_seq_length = 55\n",
        "\n",
        "#BERT takes 3 inputs\n",
        "\n",
        "#this is input words. Sequence of words represented as integers\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "#mask vector if you are padding anything\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
        "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
        "#second seq segment vector are 1's\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "#bert layer \n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "#Bert model\n",
        "#We are using only pooled output not sequence out. \n",
        "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
        "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQJsjg6fqVBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f5e34b-f049-496c-ec84-dd9e22719574"
      },
      "source": [
        "bert_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 55, 768)]                 'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,482,241\n",
            "Trainable params: 0\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3z0OMA5qVBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e059d4-302c-4801-f79f-923ddef9df46"
      },
      "source": [
        "bert_model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewv4hFCsqVBU"
      },
      "source": [
        "<pre><font size=6>Part-3: Tokenization</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX3VEFjiqVBU"
      },
      "source": [
        "#getting Vocab file\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU1kWas1oek3",
        "outputId": "fb6062fe-df67-49ce-cddb-d171bb65e55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_iPwa99qVBW"
      },
      "source": [
        "import tokenization  #We have given tokenization.py file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guJMLJ8bqVBY"
      },
      "source": [
        "# Create tokenizer \" Instantiate FullTokenizer\" \n",
        "# name must be \"tokenizer\"\n",
        "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
        "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
        "# please check the \"tokenization.py\" file the complete implementation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlGFtp2xxzt6"
      },
      "source": [
        "# if you are getting error for sentencepiece module you can install it using below command while running this cell for the first time\n",
        "#!pip install sentencepiece\n",
        "tokenizer=tokenization.FullTokenizer(vocab_file,do_lower_case )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKkGLhR-qVBd"
      },
      "source": [
        "<font size=4>Grader function 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CPu850xqVBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae5f5ac-36b3-4404-972f-71de1415ce6a"
      },
      "source": [
        "#it has to give no error \n",
        "def grader_tokenize(tokenizer):\n",
        "    out = False\n",
        "    try:\n",
        "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
        "    except:\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "grader_tokenize(tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9crhPylQqVBg"
      },
      "source": [
        "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
        "\n",
        "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
        "\n",
        "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
        "\n",
        "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
        "\n",
        "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
        "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
        "\n",
        "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
        "\n",
        "# type of all the above arrays should be numpy arrays\n",
        "\n",
        "# after execution of this cell, you have to get \n",
        "# X_train_tokens, X_train_mask, X_train_segment\n",
        "# X_test_tokens, X_test_mask, X_test_segment\n",
        "\n",
        "#generalized function to get tokens,masks,segment\n",
        "def tokens(text_input):\n",
        "  li_tokens = []\n",
        "  li_tokens_to_ids = []\n",
        "  li_mask = []\n",
        "  li_segment = []\n",
        "  \n",
        "  for i in range(len(text_input)):\n",
        "    token = tokenizer.tokenize(text_input[i])\n",
        "   \n",
        "    if(len(token) > max_seq_length - 2):\n",
        "      token = token[0:(max_seq_length - 2)]\n",
        "    token = ['[CLS]',*token,'[SEP]']\n",
        "    if(len(token) < max_seq_length):\n",
        "      pad_to_add = max_seq_length - len(token)\n",
        "      for i in range(pad_to_add):\n",
        "        token.append('[PAD]')\n",
        "      \n",
        "    #will pad the sequence to maximum sequence length\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(token)\n",
        "    li_tokens.append(token)\n",
        "    li_tokens_to_ids.append(input_ids)\n",
        "    li_mask.append([1 if(i>0) else 0 for i in input_ids])\n",
        "    li_segment.append([0] * max_seq_length)\n",
        "    \n",
        "  return np.array(li_tokens),np.array(li_tokens_to_ids),np.array(li_mask),np.array(li_segment)\n",
        "    \n",
        "\n",
        "\n",
        "X_train_tokens_,X_train_tokens,X_train_mask,X_train_segment = tokens(x_train['Text'].values)\n",
        "X_test_tokens_,X_test_tokens,X_test_mask,X_test_segment = tokens(x_test['Text'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tokens_[0])\n",
        "\n",
        "print(X_train_tokens[0])\n",
        "print(X_train_mask[0])\n",
        "print(X_train_segment[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUG-s3pQR6WE",
        "outputId": "8685d36d-6be7-467a-f795-ec9801bedb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]' 'i' 'had' 'never' 'tried' 'this' 'brand' 'before' ',' 'so' 'i'\n",
            " 'was' 'worried' 'about' 'the' 'quality' '.' 'it' 'tasted' 'great' '.' 'a'\n",
            " 'very' 'nice' 'smooth' 'rich' 'full' 'flavor' '.' 'its' 'my' 'new'\n",
            " 'favor' '##et' '.' '[SEP]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]'\n",
            " '[PAD]' '[PAD]' '[PAD]' '[PAD]' '[PAD]']\n",
            "[  101  1045  2018  2196  2699  2023  4435  2077  1010  2061  1045  2001\n",
            "  5191  2055  1996  3737  1012  2009 12595  2307  1012  1037  2200  3835\n",
            "  5744  4138  2440 14894  1012  2049  2026  2047  5684  3388  1012   102\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_tokens_[0])\n",
        "print(X_test_tokens[0])\n",
        "print(X_test_mask[0])\n",
        "print(X_test_segment[0])"
      ],
      "metadata": {
        "id": "3ogWRUAXXjvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644fe8a4-2424-459d-b013-57a51aa751a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]' 'my' 'pregnant' 'golden' '##do' '##odle' 'was' 'very' 'pick'\n",
            " '##y' 'at' 'the' 'end' 'of' 'her' 'pregnancy' 'and' 'i' 'couldn' \"'\" 't'\n",
            " 'get' 'her' 'to' 'eat' 'anything' 'other' 'than' 'chicken' 'and' 'rice'\n",
            " '(' 'homemade' ')' '.' 'this' 'food' 'was' 'a' 'life' '##sa' '##ver'\n",
            " 'for' 'her' 'and' 'her' 'pup' '##s' '.' 'she' 'absolutely' 'love' 'it'\n",
            " '.' '[SEP]']\n",
            "[  101  2026  6875  3585  3527 26156  2001  2200  4060  2100  2012  1996\n",
            "  2203  1997  2014 10032  1998  1045  2481  1005  1056  2131  2014  2000\n",
            "  4521  2505  2060  2084  7975  1998  5785  1006 25628  1007  1012  2023\n",
            "  2833  2001  1037  2166  3736  6299  2005  2014  1998  2014 26781  2015\n",
            "  1012  2016  7078  2293  2009  1012   102]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv1-t4OjqVBj"
      },
      "source": [
        "#### Example\n",
        "<img src='https://i.imgur.com/5AhhmgU.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhggBxwqVBj"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF0idMRDqVBm"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((x_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
        "pickle.dump((x_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leu1URGzqVBo"
      },
      "source": [
        "#you can load from disk\n",
        "#X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
        "#X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjPv8VkJqVBr"
      },
      "source": [
        "<font size=4>Grader function 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qekHJgmdqVBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4fe636-68a3-43dd-eeb9-f1e8d5d0a3b9"
      },
      "source": [
        "def grader_alltokens_train():\n",
        "    out = False\n",
        "    \n",
        "    if type(X_train_tokens) == np.ndarray:\n",
        "        \n",
        "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
        "        (X_train_segment.shape[1]==max_seq_length)\n",
        "        \n",
        "        segment_temp = not np.any(X_train_segment)\n",
        "        \n",
        "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
        "        \n",
        "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
        "        \n",
        "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
        "        \n",
        "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
        "      \n",
        "    else:\n",
        "        print('Type of all above token arrays should be numpy array not list')\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "\n",
        "grader_alltokens_train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnvC6X_wqVBu"
      },
      "source": [
        "<font size=4>Grader function 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av4SRMPSqVBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e90f636-87d8-442c-b65d-757fd7c0227e"
      },
      "source": [
        "def grader_alltokens_test():\n",
        "    out = False\n",
        "    if type(X_test_tokens) == np.ndarray:\n",
        "        \n",
        "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
        "        (X_test_segment.shape[1]==max_seq_length)\n",
        "        \n",
        "        segment_temp = not np.any(X_test_segment)\n",
        "        \n",
        "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
        "        \n",
        "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
        "        \n",
        "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
        "        \n",
        "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
        "      \n",
        "    else:\n",
        "        print('Type of all above token arrays should be numpy array not list')\n",
        "        out = False\n",
        "    assert(out==True)\n",
        "    return out\n",
        "grader_alltokens_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEj-Eua5qVBx"
      },
      "source": [
        "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
        "We already created the BERT model in the part-2 and input data in the part-3. \n",
        "We will utlize those two and will get the embeddings for each sentence in the \n",
        "Train and test data.</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwOVgQFDqVBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5500acfb-e632-45cc-c630-a9cfd92e0d24"
      },
      "source": [
        "bert_model.input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n",
              " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n",
              " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcpkQq1OqVB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7bc446-852a-4e85-96d4-67a8c36056a0"
      },
      "source": [
        "bert_model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdIlOIBlm7j"
      },
      "source": [
        "# get the train output, BERT model will give one output so save in\n",
        "# X_train_pooled_output\n",
        "#this cell will take some time to execute, make sure thay you have stable internet connection\n",
        "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZT11BCol4gL"
      },
      "source": [
        "# get the test output, BERT model will give one output so save in\n",
        "# X_test_pooled_output\n",
        "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL6JVojfqVB8"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "1eyZAjCs6uSB",
        "outputId": "7e2843eb-128a-4825-9b6c-c41ab016baa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9cd410d-85ce-4a0b-b6ed-e4fcb72037c5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9cd410d-85ce-4a0b-b6ed-e4fcb72037c5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSQcBdROqVB9"
      },
      "source": [
        "#X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulEXFE7aqVCA"
      },
      "source": [
        "<font size=4>Grader function 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHCsW0IvqVCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4488a3-771e-451b-b0d4-940b0d4ac7c4"
      },
      "source": [
        "#now we have X_train_pooled_output, y_train\n",
        "#X_test_pooled_ouput, y_test\n",
        "\n",
        "#please use this grader to evaluate\n",
        "def greader_output():\n",
        "    assert(X_train_pooled_output.shape[1]==768)\n",
        "    assert(len(y_train)==len(X_train_pooled_output))\n",
        "    assert(X_test_pooled_output.shape[1]==768)\n",
        "    assert(len(y_test)==len(X_test_pooled_output))\n",
        "    assert(len(y_train.shape)==1)\n",
        "    assert(len(X_train_pooled_output.shape)==2)\n",
        "    assert(len(y_test.shape)==1)\n",
        "    assert(len(X_test_pooled_output.shape)==2)\n",
        "    return True\n",
        "greader_output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8PQlYRqVCE"
      },
      "source": [
        "##imports\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM,Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = to_categorical(y_train)\n",
        "test_y = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "761O69YZvWYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gA_Xjtivdxm",
        "outputId": "1e0b5c5f-3723-46ec-838a-3695286a4e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def roc_auc(y_true, y_pred):\n",
        "    if len(np.unique(y_true[:,1])) == 1:\n",
        "        return 0.5\n",
        "    else:\n",
        "        return roc_auc_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "\n",
        "def auc(y_true, y_pred):\n",
        "    return tf.py_function(roc_auc, (y_true, y_pred), tf.double)\n"
      ],
      "metadata": {
        "id": "lJCUbCSP8326"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "XUCJgiGFxyuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "log_dir = os.path.join(\"logs\",'fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)"
      ],
      "metadata": {
        "id": "ph3eeYDV_2qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,monitor = 'val_auc',mode = \"max\",\n",
        "                                                 save_weights_only=True,save_best_only = True,\n",
        "                                                 verbose=1)\n"
      ],
      "metadata": {
        "id": "5CNla87e5wkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSnmX3WnqVCG"
      },
      "source": [
        "##create an Neural Network and train your model on X_train_pooled_output and y_train\n",
        "# you can start as follows\n",
        "input_layer=Input(shape=(X_train_pooled_output.shape[1],))\n",
        "dense_0 = Dense(256,activation = \"relu\")(input_layer)\n",
        "dense_1 = Dense(128,activation = \"relu\")(dense_0)\n",
        "drop_1 = Dropout(0.5)(dense_1)\n",
        "dense_2 = Dense(64,activation= 'relu')(drop_1)\n",
        "drop_2 = Dropout(0.5)(dense_2)\n",
        "dense_3 = Dense(32,activation='relu')(drop_2)\n",
        "drop_3 = Dropout(0.5)(dense_3)\n",
        "dense_4 = Dense(16,activation = \"relu\")(drop_3)\n",
        "out = Dense(2,activation = \"softmax\")(dense_4)\n",
        "model = Model(inputs = input_layer,outputs = out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\",metrics = [auc])\n",
        "model.fit(x = X_train_pooled_output,y = train_y,epochs = 20,validation_split = 0.2,callbacks = [tensorboard_callback,cp_callback])"
      ],
      "metadata": {
        "id": "SLTqQrU_AOaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803b1475-21c9-4e5c-adfd-3c80c9c3b3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.3078 - auc: 0.8136\n",
            "Epoch 1: val_auc improved from -inf to 0.93028, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 23s 11ms/step - loss: 0.3078 - auc: 0.8139 - val_loss: 0.2264 - val_auc: 0.9303\n",
            "Epoch 2/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.2309 - auc: 0.9208\n",
            "Epoch 2: val_auc improved from 0.93028 to 0.93774, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.2310 - auc: 0.9208 - val_loss: 0.2962 - val_auc: 0.9377\n",
            "Epoch 3/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.2161 - auc: 0.9318\n",
            "Epoch 3: val_auc improved from 0.93774 to 0.94557, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.2161 - auc: 0.9318 - val_loss: 0.2145 - val_auc: 0.9456\n",
            "Epoch 4/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.2105 - auc: 0.9333\n",
            "Epoch 4: val_auc improved from 0.94557 to 0.94572, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.2103 - auc: 0.9334 - val_loss: 0.2379 - val_auc: 0.9457\n",
            "Epoch 5/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.2061 - auc: 0.9348\n",
            "Epoch 5: val_auc improved from 0.94572 to 0.94768, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.2060 - auc: 0.9348 - val_loss: 0.2073 - val_auc: 0.9477\n",
            "Epoch 6/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.2008 - auc: 0.9397\n",
            "Epoch 6: val_auc improved from 0.94768 to 0.94816, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.2008 - auc: 0.9398 - val_loss: 0.2659 - val_auc: 0.9482\n",
            "Epoch 7/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.2008 - auc: 0.9392\n",
            "Epoch 7: val_auc did not improve from 0.94816\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.2008 - auc: 0.9393 - val_loss: 0.2505 - val_auc: 0.9452\n",
            "Epoch 8/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1948 - auc: 0.9410\n",
            "Epoch 8: val_auc improved from 0.94816 to 0.95140, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1947 - auc: 0.9410 - val_loss: 0.2129 - val_auc: 0.9514\n",
            "Epoch 9/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1958 - auc: 0.9399\n",
            "Epoch 9: val_auc did not improve from 0.95140\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1958 - auc: 0.9398 - val_loss: 0.3521 - val_auc: 0.9506\n",
            "Epoch 10/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1957 - auc: 0.9438\n",
            "Epoch 10: val_auc did not improve from 0.95140\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1957 - auc: 0.9438 - val_loss: 0.2830 - val_auc: 0.9511\n",
            "Epoch 11/20\n",
            "1994/2000 [============================>.] - ETA: 0s - loss: 0.1943 - auc: 0.9425\n",
            "Epoch 11: val_auc did not improve from 0.95140\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1943 - auc: 0.9426 - val_loss: 0.2783 - val_auc: 0.9419\n",
            "Epoch 12/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1963 - auc: 0.9426\n",
            "Epoch 12: val_auc did not improve from 0.95140\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1964 - auc: 0.9425 - val_loss: 0.3018 - val_auc: 0.9512\n",
            "Epoch 13/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1924 - auc: 0.9425\n",
            "Epoch 13: val_auc improved from 0.95140 to 0.95254, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1924 - auc: 0.9426 - val_loss: 0.2283 - val_auc: 0.9525\n",
            "Epoch 14/20\n",
            "1994/2000 [============================>.] - ETA: 0s - loss: 0.1921 - auc: 0.9456\n",
            "Epoch 14: val_auc did not improve from 0.95254\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1920 - auc: 0.9457 - val_loss: 0.2268 - val_auc: 0.9505\n",
            "Epoch 15/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1887 - auc: 0.9430\n",
            "Epoch 15: val_auc improved from 0.95254 to 0.95309, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1886 - auc: 0.9430 - val_loss: 0.2167 - val_auc: 0.9531\n",
            "Epoch 16/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1872 - auc: 0.9469\n",
            "Epoch 16: val_auc improved from 0.95309 to 0.95315, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1872 - auc: 0.9470 - val_loss: 0.2023 - val_auc: 0.9532\n",
            "Epoch 17/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1874 - auc: 0.9440\n",
            "Epoch 17: val_auc did not improve from 0.95315\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1874 - auc: 0.9440 - val_loss: 0.3077 - val_auc: 0.9488\n",
            "Epoch 18/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1892 - auc: 0.9450\n",
            "Epoch 18: val_auc improved from 0.95315 to 0.95362, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1892 - auc: 0.9450 - val_loss: 0.1812 - val_auc: 0.9536\n",
            "Epoch 19/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1857 - auc: 0.9468\n",
            "Epoch 19: val_auc improved from 0.95362 to 0.95424, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1857 - auc: 0.9468 - val_loss: 0.3259 - val_auc: 0.9542\n",
            "Epoch 20/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1866 - auc: 0.9461\n",
            "Epoch 20: val_auc did not improve from 0.95424\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1865 - auc: 0.9461 - val_loss: 0.1841 - val_auc: 0.9539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa28854d350>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "model.fit(x = X_train_pooled_output,y = train_y,epochs = 20,validation_split = 0.2,callbacks = [tensorboard_callback,cp_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxqDGlRsBhl1",
        "outputId": "22881937-22e7-4e14-af75-566e6482d4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1841 - auc: 0.9473\n",
            "Epoch 1: val_auc did not improve from 0.95424\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1843 - auc: 0.9472 - val_loss: 0.3061 - val_auc: 0.9532\n",
            "Epoch 2/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1876 - auc: 0.9484\n",
            "Epoch 2: val_auc improved from 0.95424 to 0.95496, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1876 - auc: 0.9483 - val_loss: 0.2418 - val_auc: 0.9550\n",
            "Epoch 3/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1840 - auc: 0.9481\n",
            "Epoch 3: val_auc did not improve from 0.95496\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1840 - auc: 0.9481 - val_loss: 0.2552 - val_auc: 0.9547\n",
            "Epoch 4/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1842 - auc: 0.9481\n",
            "Epoch 4: val_auc improved from 0.95496 to 0.95536, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1842 - auc: 0.9481 - val_loss: 0.2633 - val_auc: 0.9554\n",
            "Epoch 5/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1861 - auc: 0.9483\n",
            "Epoch 5: val_auc improved from 0.95536 to 0.95591, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1861 - auc: 0.9483 - val_loss: 0.1906 - val_auc: 0.9559\n",
            "Epoch 6/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1836 - auc: 0.9477\n",
            "Epoch 6: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1837 - auc: 0.9477 - val_loss: 0.1960 - val_auc: 0.9557\n",
            "Epoch 7/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1847 - auc: 0.9483\n",
            "Epoch 7: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1848 - auc: 0.9482 - val_loss: 0.1906 - val_auc: 0.9524\n",
            "Epoch 8/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1858 - auc: 0.9481\n",
            "Epoch 8: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1858 - auc: 0.9481 - val_loss: 0.2516 - val_auc: 0.9534\n",
            "Epoch 9/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1831 - auc: 0.9481\n",
            "Epoch 9: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1830 - auc: 0.9481 - val_loss: 0.3145 - val_auc: 0.9515\n",
            "Epoch 10/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1810 - auc: 0.9492\n",
            "Epoch 10: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1810 - auc: 0.9492 - val_loss: 0.2218 - val_auc: 0.9539\n",
            "Epoch 11/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1799 - auc: 0.9469\n",
            "Epoch 11: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1799 - auc: 0.9470 - val_loss: 0.2461 - val_auc: 0.9539\n",
            "Epoch 12/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1826 - auc: 0.9463\n",
            "Epoch 12: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1825 - auc: 0.9463 - val_loss: 0.2546 - val_auc: 0.9540\n",
            "Epoch 13/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1804 - auc: 0.9484\n",
            "Epoch 13: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1804 - auc: 0.9484 - val_loss: 0.1983 - val_auc: 0.9538\n",
            "Epoch 14/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1802 - auc: 0.9481\n",
            "Epoch 14: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1804 - auc: 0.9481 - val_loss: 0.2199 - val_auc: 0.9540\n",
            "Epoch 15/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1800 - auc: 0.9473\n",
            "Epoch 15: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1800 - auc: 0.9473 - val_loss: 0.3135 - val_auc: 0.9511\n",
            "Epoch 16/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1821 - auc: 0.9495\n",
            "Epoch 16: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1820 - auc: 0.9495 - val_loss: 0.2457 - val_auc: 0.9554\n",
            "Epoch 17/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1807 - auc: 0.9497\n",
            "Epoch 17: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 20s 10ms/step - loss: 0.1807 - auc: 0.9497 - val_loss: 0.3311 - val_auc: 0.9506\n",
            "Epoch 18/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1793 - auc: 0.9484\n",
            "Epoch 18: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1791 - auc: 0.9484 - val_loss: 0.2158 - val_auc: 0.9550\n",
            "Epoch 19/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1790 - auc: 0.9483\n",
            "Epoch 19: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1790 - auc: 0.9483 - val_loss: 0.2631 - val_auc: 0.9549\n",
            "Epoch 20/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1810 - auc: 0.9502\n",
            "Epoch 20: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1811 - auc: 0.9502 - val_loss: 0.2535 - val_auc: 0.9548\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa281bfd250>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "model.fit(x = X_train_pooled_output,y = train_y,epochs = 20,validation_split = 0.2,callbacks = [tensorboard_callback,cp_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrwzH6X2cFiB",
        "outputId": "0a65bafe-87d9-47f7-c59f-449d300743d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1841 - auc: 0.9486\n",
            "Epoch 1: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1841 - auc: 0.9486 - val_loss: 0.2737 - val_auc: 0.9483\n",
            "Epoch 2/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1817 - auc: 0.9489\n",
            "Epoch 2: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1817 - auc: 0.9490 - val_loss: 0.2725 - val_auc: 0.9550\n",
            "Epoch 3/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1839 - auc: 0.9491\n",
            "Epoch 3: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1839 - auc: 0.9492 - val_loss: 0.2517 - val_auc: 0.9558\n",
            "Epoch 4/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1815 - auc: 0.9483\n",
            "Epoch 4: val_auc did not improve from 0.95591\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1815 - auc: 0.9483 - val_loss: 0.2109 - val_auc: 0.9548\n",
            "Epoch 5/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1834 - auc: 0.9480\n",
            "Epoch 5: val_auc improved from 0.95591 to 0.95611, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1834 - auc: 0.9480 - val_loss: 0.2092 - val_auc: 0.9561\n",
            "Epoch 6/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1843 - auc: 0.9471\n",
            "Epoch 6: val_auc improved from 0.95611 to 0.95629, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1843 - auc: 0.9471 - val_loss: 0.2544 - val_auc: 0.9563\n",
            "Epoch 7/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1815 - auc: 0.9508\n",
            "Epoch 7: val_auc did not improve from 0.95629\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1815 - auc: 0.9508 - val_loss: 0.2227 - val_auc: 0.9528\n",
            "Epoch 8/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1835 - auc: 0.9501\n",
            "Epoch 8: val_auc did not improve from 0.95629\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1834 - auc: 0.9501 - val_loss: 0.1882 - val_auc: 0.9557\n",
            "Epoch 9/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1817 - auc: 0.9486\n",
            "Epoch 9: val_auc improved from 0.95629 to 0.95672, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1817 - auc: 0.9486 - val_loss: 0.1955 - val_auc: 0.9567\n",
            "Epoch 10/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1811 - auc: 0.9508\n",
            "Epoch 10: val_auc did not improve from 0.95672\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1811 - auc: 0.9508 - val_loss: 0.2622 - val_auc: 0.9526\n",
            "Epoch 11/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1817 - auc: 0.9487\n",
            "Epoch 11: val_auc did not improve from 0.95672\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1817 - auc: 0.9487 - val_loss: 0.2442 - val_auc: 0.9562\n",
            "Epoch 12/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1808 - auc: 0.9511\n",
            "Epoch 12: val_auc did not improve from 0.95672\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1808 - auc: 0.9512 - val_loss: 0.1904 - val_auc: 0.9561\n",
            "Epoch 13/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1791 - auc: 0.9491\n",
            "Epoch 13: val_auc improved from 0.95672 to 0.95693, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1791 - auc: 0.9491 - val_loss: 0.2223 - val_auc: 0.9569\n",
            "Epoch 14/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1802 - auc: 0.9497\n",
            "Epoch 14: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1803 - auc: 0.9497 - val_loss: 0.2997 - val_auc: 0.9546\n",
            "Epoch 15/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1806 - auc: 0.9485\n",
            "Epoch 15: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1807 - auc: 0.9484 - val_loss: 0.1871 - val_auc: 0.9526\n",
            "Epoch 16/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1813 - auc: 0.9478\n",
            "Epoch 16: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1813 - auc: 0.9478 - val_loss: 0.2137 - val_auc: 0.9533\n",
            "Epoch 17/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1796 - auc: 0.9489\n",
            "Epoch 17: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1796 - auc: 0.9487 - val_loss: 0.2782 - val_auc: 0.9540\n",
            "Epoch 18/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1803 - auc: 0.9489\n",
            "Epoch 18: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1805 - auc: 0.9487 - val_loss: 0.2899 - val_auc: 0.9546\n",
            "Epoch 19/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1805 - auc: 0.9512\n",
            "Epoch 19: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1805 - auc: 0.9512 - val_loss: 0.1911 - val_auc: 0.9559\n",
            "Epoch 20/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1787 - auc: 0.9487\n",
            "Epoch 20: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1787 - auc: 0.9487 - val_loss: 0.2486 - val_auc: 0.9544\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa281babd10>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "model.fit(x = X_train_pooled_output,y = train_y,epochs = 20,validation_split = 0.2,callbacks = [tensorboard_callback,cp_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPKz9s7deKOC",
        "outputId": "04d05a5d-7fb6-4c64-d936-a9a88e1e81f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1822 - auc: 0.9475\n",
            "Epoch 1: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 23s 11ms/step - loss: 0.1822 - auc: 0.9476 - val_loss: 0.2610 - val_auc: 0.9563\n",
            "Epoch 2/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1781 - auc: 0.9501\n",
            "Epoch 2: val_auc did not improve from 0.95693\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1781 - auc: 0.9501 - val_loss: 0.1894 - val_auc: 0.9563\n",
            "Epoch 3/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1792 - auc: 0.9522\n",
            "Epoch 3: val_auc improved from 0.95693 to 0.95747, saving model to training_1/cp.ckpt\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1792 - auc: 0.9522 - val_loss: 0.1940 - val_auc: 0.9575\n",
            "Epoch 4/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1794 - auc: 0.9514\n",
            "Epoch 4: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1795 - auc: 0.9514 - val_loss: 0.1868 - val_auc: 0.9567\n",
            "Epoch 5/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1790 - auc: 0.9514\n",
            "Epoch 5: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1790 - auc: 0.9514 - val_loss: 0.2142 - val_auc: 0.9571\n",
            "Epoch 6/20\n",
            "1995/2000 [============================>.] - ETA: 0s - loss: 0.1783 - auc: 0.9503\n",
            "Epoch 6: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1784 - auc: 0.9501 - val_loss: 0.2203 - val_auc: 0.9569\n",
            "Epoch 7/20\n",
            "1998/2000 [============================>.] - ETA: 0s - loss: 0.1825 - auc: 0.9451\n",
            "Epoch 7: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1825 - auc: 0.9452 - val_loss: 0.2352 - val_auc: 0.9539\n",
            "Epoch 8/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1799 - auc: 0.9453\n",
            "Epoch 8: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1798 - auc: 0.9453 - val_loss: 0.2202 - val_auc: 0.9550\n",
            "Epoch 9/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1779 - auc: 0.9475\n",
            "Epoch 9: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1779 - auc: 0.9476 - val_loss: 0.2414 - val_auc: 0.9553\n",
            "Epoch 10/20\n",
            "1994/2000 [============================>.] - ETA: 0s - loss: 0.1780 - auc: 0.9485\n",
            "Epoch 10: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1780 - auc: 0.9485 - val_loss: 0.2428 - val_auc: 0.9552\n",
            "Epoch 11/20\n",
            "1993/2000 [============================>.] - ETA: 0s - loss: 0.1794 - auc: 0.9489\n",
            "Epoch 11: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 18s 9ms/step - loss: 0.1794 - auc: 0.9486 - val_loss: 0.2401 - val_auc: 0.9551\n",
            "Epoch 12/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1772 - auc: 0.9499\n",
            "Epoch 12: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 9ms/step - loss: 0.1772 - auc: 0.9500 - val_loss: 0.2397 - val_auc: 0.9530\n",
            "Epoch 13/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1777 - auc: 0.9512\n",
            "Epoch 13: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1777 - auc: 0.9512 - val_loss: 0.1936 - val_auc: 0.9557\n",
            "Epoch 14/20\n",
            "1997/2000 [============================>.] - ETA: 0s - loss: 0.1785 - auc: 0.9496\n",
            "Epoch 14: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 21s 10ms/step - loss: 0.1785 - auc: 0.9496 - val_loss: 0.2308 - val_auc: 0.9551\n",
            "Epoch 15/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1781 - auc: 0.9502\n",
            "Epoch 15: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1781 - auc: 0.9502 - val_loss: 0.2956 - val_auc: 0.9527\n",
            "Epoch 16/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1771 - auc: 0.9506\n",
            "Epoch 16: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1770 - auc: 0.9506 - val_loss: 0.1765 - val_auc: 0.9557\n",
            "Epoch 17/20\n",
            "1999/2000 [============================>.] - ETA: 0s - loss: 0.1763 - auc: 0.9511\n",
            "Epoch 17: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1763 - auc: 0.9511 - val_loss: 0.3040 - val_auc: 0.9528\n",
            "Epoch 18/20\n",
            "1996/2000 [============================>.] - ETA: 0s - loss: 0.1765 - auc: 0.9511\n",
            "Epoch 18: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 22s 11ms/step - loss: 0.1764 - auc: 0.9511 - val_loss: 0.1984 - val_auc: 0.9554\n",
            "Epoch 19/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1761 - auc: 0.9512\n",
            "Epoch 19: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 19s 10ms/step - loss: 0.1761 - auc: 0.9512 - val_loss: 0.2361 - val_auc: 0.9550\n",
            "Epoch 20/20\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 0.1753 - auc: 0.9507\n",
            "Epoch 20: val_auc did not improve from 0.95747\n",
            "2000/2000 [==============================] - 21s 11ms/step - loss: 0.1753 - auc: 0.9507 - val_loss: 0.2269 - val_auc: 0.9558\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa28693f950>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "model.fit(x = X_train_pooled_output,y = train_y,epochs = 20,validation_split = 0.2,callbacks = [tensorboard_callback,cp_callback])"
      ],
      "metadata": {
        "id": "ZUVn3EK7fxXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(X_test_pooled_output,test_y,verbose  = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewoz2Kc17-e1",
        "outputId": "13ae3ebc-cb5a-49c5-a0d2-8f22759283ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2278 - auc: 0.9486\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22776640951633453, 0.9485718607902527]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}